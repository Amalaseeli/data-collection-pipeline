# Data Collection Pipeline


### It uses Python code to automatically control your browser, extract information from a website

### Packages and Installation
<ul>
<li>Selenium</li>
<li>Web driver</li>
</ul>

### Basic steps:
<ol>
<li>Here let's scrap data from <a href="https://www.myprotein.com/">myprotein</a> website.</li>
<li>Search for category protein bar</li>
<li>Find links for each item</li>
<li>Retrieve data for each item</li>
<li>Save the raw_dictionaries locally </li>
<li>Find image links and download image locally</li>

</ol>


### <b>Note: The system conforms running automated testing</b>
### This application uses a CI/CD pipeline with the help of DockerContainer and Github actions for automating the applications build, test and deployment process.






